{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Introduction to pandas\n",
    "\n",
    "In this part we are going to explain some basic concepts in pandas and how to work with Pandas on simple datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the Pandas library in a virtual environment\n",
    "\n",
    "To use this pandas notebook it is good pratice to build a virtual environment first and then activate it.\n",
    "\n",
    "To do this go to the directory in the terminal where you cloned this repository and type: `python3 -m venv venv`.\n",
    "\n",
    "This should create an environment that you can activate by typing: `source ./venv/bin/activate`.\n",
    "Now the prompt in your terminal should start with `(venv)` and you can start installing libraries without messing with the rest of you systems.\n",
    "\n",
    "For a detailed tutorial on how to use virtual environments the site https://realpython.com/python-virtual-environments-a-primer/ is a good bit somewhat outdated start. Planning on creating my own one soon..\n",
    "\n",
    "NB: If you are using source control you must also create a file called `.gitignore` in the root directory of this project and type `venv/` and save it. Otherwise the environment is stored in your repository.\n",
    "\n",
    "Now we are ready to import the panda library using `!pip install pandas` in the notebook to install the Pandas module and import it in our notebook.\n",
    "\n",
    "We use `as pd` as a convention to alias the library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing pandas\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas in the project. As a convention we import the library with the \n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to a dataframes.\n",
    "\n",
    "The 3 components of pandas are the \"Index\", \"Series\" and \"DataFrame\".\n",
    "\n",
    "A Series is one column, and a DataFrame is a one or more columns combined, together with a unique index.\n",
    "Series is something we will touch on later in this course. Lets first explore the main component, namely the dataframe.\n",
    "\n",
    "Let's see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of first names\n",
    "firstnames = ['John', 'Peter', 'Francis', 'Bob', 'Mary']\n",
    "# turn it into a dataframe\n",
    "df = pd.DataFrame(firstnames)\n",
    "# and inspect what we have\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we now have something that resembles a spreadsheet. Although there are some notable differences:\n",
    "* The rows start with a '0' instead of '1'.\n",
    "* The column also has a '0' as a header and not 'firstnames' or an 'A' as you may be familiar with in a spreadsheet.\n",
    "Let's add another column.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of last names\n",
    "lastnames = ['Doe','Parker','Bacon','Smith','Poppins']\n",
    "# make a list of both the lists that we have\n",
    "names = [firstnames,lastnames]\n",
    "# turn it into a dataframe again\n",
    "df = pd.DataFrame(names)\n",
    "# and inspect what we have\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly not the intended result! We wanted a the firstnames and the lastnames in columns not rows. To accomplish this we need to put the the lists in a different order. We need to specify the rows that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of names\n",
    "names = [['John','Doe'],['Peter','Parker'],['Frances','Bacon'],['Bob','Smith'],['Mary','Poppins']]\n",
    "# turn it into a dataframe again\n",
    "df = pd.DataFrame(names)\n",
    "# and inspect what we have\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better but very tedious as we want the data to be added as lists of first names and last names. To accomplish the we need to put the data in a Python dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\"A\":firstnames,\"B\":lastnames}\n",
    "# turn it into a dataframe again\n",
    "df = pd.DataFrame(names)\n",
    "# and inspect what we have\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! a spreadsheet, albeit with the rows starting at 0.. But as you may have noticed, we can now change the column names to something more usefull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {\"First names\":firstnames,\"Last names\":lastnames}\n",
    "# turn it into a dataframe again\n",
    "df = pd.DataFrame(names)\n",
    "# and inspect what we have\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still left with the rows starting a \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = [1,2,3,4,5]\n",
    "# or better\n",
    "index = list(range(1,len(firstnames)+1))\n",
    "# turn it into a dataframe again but now with index\n",
    "df = pd.DataFrame(names, index=index)\n",
    "# and inspect what we have\n",
    "df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks what we are after!\n",
    "\n",
    "Or not.. Unless you are sure you should keep the index as is. We will see some situations were adding a custom index is a smart idea late in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"First names\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing data from a file\n",
    "\n",
    "Typing in a complete dataset is seldom a good idea. More often you ar provided a dataset that you will be working on. That is what this part is about. We will explore the import of datasets in very basic form like Excel and .csv format and look how this works. Later parts will touch on several other formats as well as connecting to databases, that you might encounter in a more real world scenario.\n",
    "\n",
    "Lets first import a simple csv-file. CSV stands for \"comma seperated file\" and is a widely used format to export data from one application to another.\n",
    "\n",
    "I compiled a csv-file of the best tennis players of all time in another course about webscraping. Lets use this dataset for our purpose. you can find the source at this link: https://howtheyplay.com/individual-sports/Top-10-Greatest-Male-Tennis-Players-of-All-Time. I have taken a sports dataset specifically because it is a well known subject and the datasets around it are very detailed and rich. Very handy later on this course to explain all concepts of Pandas, data engineering and data science. Tennis is not my favorite sport, but after looking at several other sport datasets, I found this one to be very usefull to show the different scenario's that anyone may encounter in data.\\\n",
    "NB: please do not bug me with questions that Boris Becker or some other person is not included. We will come to that later in the course if we touch on unstructured data.\n",
    "\n",
    "First we will import a simple dataset in CSV.\n",
    "\n",
    "I compiled the the webpage in a csv file that looks like this:\n",
    "\n",
    "`id,name,dob,pob,cob,por,cor,pro,retired,price,wins,aus,fra,usa,eng,olympic,thof`\\\n",
    "`11,Ken Rosewall,1934-11-02,Sydney,Australia,Sydney,Australia,1957,1980,1602700,133,4,10,4,5,0,1980`\\\n",
    "`10,Andre Agassi,1970-04-29,Las Vegas,United States,Las Vegas,United States,1986,2006,315275,61,4,1,2,1,1,2011`\\\n",
    "`9,John McEnroe,1959-02-16,Wiesbaden,West Germany,New York City,United States,1978,1992,12547797,105,0,0,4,3,0,1999`\\\n",
    "`8,Jimmy Connors,1952-09-02,East St-Louis,United States,Santa Barbara,United States,1972,1996,8641040,147,1,0,2,5,0,1998`\\\n",
    "`7,Ivan Lendl,1960-03-07,Ostrava,Czechoslovakia,Goshen,United States,1978,1994,21262417,144,2,3,3,0,0,2001`\\\n",
    "`6,Bjorn Borg,1956-06-06,Sodertalje,Sweden,Stockholm,Sweden,1973,1983,3655751,101,0,6,0,5,0,1987`\\\n",
    "`5,Pete Sampras,1971-07-12,Potomac,United States,Lake Sherwood,United States,1988,2002,43280489,64,2,0,5,7,0,2007`\\\n",
    "`4,Rod Laver,1938-07-08,Rockhampton,Australia,Carlsbad,United States,1962,1979,1565413,200,3,3,5,9,0,1981`\\\n",
    "`3,Roger Federer,1981-07-08,Basel,Switzerland,Bottmingen,Switzerland,1998,,130594339,103,6,1,5,8,0,`\\\n",
    "`2,Rafael Nadal,1986-06-03,Manacor,Spain,Manacor,Spain,2001,,134529921,92,14,2,4,2,1,2022`\\\n",
    "`1,Novak Djokovic,1987-05-22,Belgrade,Serbia,Monte Carlo,Monaco,2003,,164786653,93,10,2,3,7,0,`\n",
    "\n",
    "in columnar format this looks like:\n",
    "| id | name           | dob        | pob           | cob            | por           | cor           | pro  | retired | price     | wins | aus | fra | usa | eng | olympic | thof |\n",
    "|----|----------------|------------|---------------|----------------|---------------|---------------|------|---------|-----------|------|-----|-----|-----|-----|---------|------|\n",
    "| 11 | Ken Rosewall   | 1934-11-02 | Sydney        | Australia      | Sydney        | Australia     | 1957 | 1980    | 1602700   | 133  | 4   | 10  | 4   | 5   | 0       | 1980 |\n",
    "| 10 | Andre Agassi   | 1970-04-29 | Las Vegas     | United States  | Las Vegas     | United States | 1986 | 2006    | 315275    | 61   | 4   | 1   | 2   | 1   | 1       | 2011 |\n",
    "| 9  | John McEnroe   | 1959-02-16 | Wiesbaden     | West Germany   | New York City | United States | 1978 | 1992    | 12547797  | 105  | 0   | 0   | 4   | 3   | 0       | 1999 |\n",
    "| 8  | Jimmy Connors  | 1952-09-02 | East St-Louis | United States  | Santa Barbara | United States | 1972 | 1996    | 8641040   | 147  | 1   | 0   | 2   | 5   | 0       | 1998 |\n",
    "| 7  | Ivan Lendl     | 1960-03-07 | Ostrava       | Czechoslovakia | Goshen        | United States | 1978 | 1994    | 21262417  | 144  | 2   | 3   | 3   | 0   | 0       | 2001 |\n",
    "| 6  | Bjorn Borg     | 1956-06-06 | Sodertalje    | Sweden         | Stockholm     | Sweden        | 1973 | 1983    | 3655751   | 101  | 0   | 6   | 0   | 5   | 0       | 1987 |\n",
    "| 5  | Pete Sampras   | 1971-07-12 | Potomac       | United States  | Lake Sherwood | United States | 1988 | 2002    | 43280489  | 64   | 2   | 0   | 5   | 7   | 0       | 2007 |\n",
    "| 4  | Rod Laver      | 1938-07-08 | Rockhampton   | Australia      | Carlsbad      | United States | 1962 | 1979    | 1565413   | 200  | 3   | 3   | 5   | 9   | 0       | 1981 |\n",
    "| 3  | Roger Federer  | 1981-07-08 | Basel         | Switzerland    | Bottmingen    | Switzerland   | 1998 |         | 130594339 | 103  | 6   | 1   | 5   | 8   | 0       |      |\n",
    "| 2  | Rafael Nadal   | 1986-06-03 | Manacor       | Spain          | Manacor       | Spain         | 2001 |         | 134529921 | 92   | 14  | 2   | 4   | 2   | 1       |      |\n",
    "| 1  | Novak Djokovic | 1987-05-22 | Belgrade      | Serbia         | Monte Carlo   | Monaco        | 2003 |         | 164786653 | 93   | 10  | 2   | 3   | 7   | 0       |      |\n",
    "\n",
    "To create a dataframe out of this in Pandas is very easy. Pass the path to the file to the `read_csv` method like so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv file and inspect\n",
    "df = pd.read_csv(\"../tennis-data/10tennisplayer.csv\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we look at this result we can make a few observations:\n",
    "* As seen previously, the index is set by Pandas. We might wanna change that to the 'Place' column.\n",
    "* The 'Place' column is descending.\n",
    "* The turned-pro column looks good, but the 'retired' and hall-of-fame column are integers but floating points.\n",
    "* Also these columns have NaN (which stands for \"Not a Number\") values for some of the values.\n",
    "\n",
    "Lets tackle the first two issues first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the column that we want to use as index\n",
    "df = pd.read_csv(\"../tennis-data/10tennisplayer.csv\",index_col=\"Place\")\n",
    "# sort them in ascending order\n",
    "df.sort_index(inplace=True)\n",
    "# display\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila, We have our dataframe. We can do the same with an excel sheet.\n",
    "For this pandas is dependend on openpyxl so we will have to import that first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create a dataframe from an excel sheet. Be ware that the sheet needs to be a continuous set of rows and columns. Otherwise you will run into errors. You can pass a sheet name to identify the worksheet that contains the data.\n",
    "\n",
    "In a later tutorial we will go into detail about working with excel sheets and see how we can work with formulas, tables, named ranges and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel = pd.read_excel(\"../tennis-data/top10tennisplayers.xlsx\", index_col=\"Place\", sheet_name=\"Sheet1\")\n",
    "df_excel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it works just as a regular csv file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inspecting a data frame\n",
    "\n",
    "We now have a data frame created, albeit a very small one. By typing `df` in Jupyter we can inspect it's content, as if we were doing a print statement. A dataframe is a very usefull format to work with columnar data as we will see later in this tutorial.\n",
    "\n",
    "In this section we are going to explain how to inspect this data format and the functions that help see what the data is so we can use that later to enrich and transform it in usefull information.\n",
    "\n",
    "Printing `df` is fine for a small dataset, but when we have thousands of rows, this is not what we desire. If we just want to inspect the first rows another function is more used and recommended.\n",
    "\n",
    "The first ones are `head` and `tail` to view either the first or last row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[1,\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.get([\"Name\",\"Retired\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\"Retired\":\"Int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\"Birth date\":\"datetime64\",\"Price money\":\"float64\"})\n",
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
